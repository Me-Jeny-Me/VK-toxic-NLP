{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk \n",
    "import sklearn \n",
    "from sklearn import*\n",
    "import re \n",
    "from tqdm import tqdm \n",
    "import catboost as ctb\n",
    "import joblib\n",
    "from collections import*\n",
    "tqdm.pandas()\n",
    "import pymystem3\n",
    "import pymorphy2\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hatred_upper(text):\n",
    "    upper = len([i for i in text if i.isupper()])\n",
    "    lower = len([i for i in text if i.islower()])\n",
    "    return upper/(upper+lower+1e-6)\n",
    "\n",
    "def hatred_punc(text):\n",
    "    punct = len(re.findall(r'[^\\w\\s]',text))\n",
    "    text = len(re.findall(r'\\w+',text))\n",
    "    return punct/(text+1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FE(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns=['text']\n",
    "    df['upper'] = df.text.apply(hatred_upper)\n",
    "    df['punct'] = df.text.apply(hatred_punc)\n",
    "    df['title'] = df.text.apply(lambda x: len([i for i in x if i.istitle()==True]))\n",
    "    df['len'] = df.text.apply(len)\n",
    "    df['count'] = df.text.apply(lambda x: len(x.split()))\n",
    "    df['average_len'] = df.text.apply(lambda x: np.mean([len(i) for i in x.split()])).fillna(0)\n",
    "    df['pos_sc'] = df.text.apply(lambda text: len(re.findall(r'\\)|D',text)))\n",
    "    df['neg_sc'] = df.text.apply(lambda text: len(re.findall(r'\\(|C|c|С|c',text)))\n",
    "    df = df.drop('text',axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_clear(df):\n",
    "    df=pd.Series(df,name='text')\n",
    "    compilers = [re.compile(r'(#|@)\\w+'),\\\n",
    "                        re.compile(r'htt(ps|p)\\S+'),\\\n",
    "                        re.compile(r'_+')]\n",
    "    for comp in compilers:\n",
    "        df = df.apply(lambda line: re.sub(comp,'',line))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymy(text):\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    normal_text=' '.join([morph.parse(x)[0].normal_form for x in text.split()])\n",
    "    return normal_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    " stopwords = nltk.corpus.stopwords.words('russian')\n",
    " def stopwords_clear (text):\n",
    "        return ' '.join([w for w in text.split() if w.lower() not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmize(df,parts=5):\n",
    "    m = pymystem3.Mystem()\n",
    "    df=[' '.join(re.findall(r'[А-я]+',line)) for line in df]\n",
    "    batch=len(df)//parts\n",
    "    for i in tqdm(range(parts)):\n",
    "        batch_df='|'.join(df[i*batch:(i+1)*batch])\n",
    "        lem_batch_df=''.join(m.lemmatize(batch_df)).split('|')\n",
    "        df[i*batch:(i+1)*batch] = lem_batch_df           \n",
    "    lem_df=pd.Series(df,name='text')\n",
    "    lem_df = lem_df.apply(stopwords_clear)\n",
    "    return lem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=re_clear(df['ttext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=FE(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 5/5 [02:15<00:00, 27.03s/it]\nWall time: 2min 19s\n"
    }
   ],
   "source": [
    "%%time\n",
    "lemmized_st = lemmize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_vec = feature_extraction.text.TfidfVectorizer(max_features=1000,ngram_range=(1,1))\n",
    "clf = naive_bayes.MultinomialNB(alpha=5)\n",
    "pipe = pipeline.Pipeline([('idf',idf_vec),('clf',clf)])\n",
    "prms = {'idf__max_features':np.arange(100,5000,500),\n",
    "'idf__ngram_range':[(1,1),(1,2),(2,2),(1,3),(2,3),(1,4)],\n",
    "'clf__alpha': [1,5,10,15,20,25,30,40,50,80]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=model_selection.RandomizedSearchCV(pipe,prms,cv=5,scoring='f1',verbose=10,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.0s\n[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   30.0s\n[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   34.4s\n[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   49.5s\n[Parallel(n_jobs=-1)]: Done  33 out of  50 | elapsed:  1.0min remaining:   31.2s\n[Parallel(n_jobs=-1)]: Done  39 out of  50 | elapsed:  1.3min remaining:   21.3s\n[Parallel(n_jobs=-1)]: Done  45 out of  50 | elapsed:  1.3min remaining:    8.7s\n[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomizedSearchCV(cv=5,\n                   estimator=Pipeline(steps=[('idf',\n                                              TfidfVectorizer(max_features=1000)),\n                                             ('clf', MultinomialNB(alpha=5))]),\n                   n_jobs=-1,\n                   param_distributions={'clf__alpha': [1, 5, 10, 15, 20, 25, 30,\n                                                       40, 50, 80],\n                                        'idf__max_features': array([ 100,  600, 1100, 1600, 2100, 2600, 3100, 3600, 4100, 4600]),\n                                        'idf__ngram_range': [(1, 1), (1, 2),\n                                                             (2, 2), (1, 3),\n                                                             (2, 3), (1, 4)]},\n                   scoring='f1', verbose=10)"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "rs.fit(text,df['ttype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_pipe = pipe.set_params(**rs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('idf', TfidfVectorizer(max_features=4100, ngram_range=(1, 2))),\n                ('clf', MultinomialNB(alpha=40))])"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "opt_pipe.fit(text,df.ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'CV roc-auc score : 71.5345%'"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "f\"CV F1 score : {np.mean(model_selection.cross_val_score(opt_pipe,text,df.ttype,cv=3,scoring='f1')):0.4%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp(text,model,lemmize=False):\n",
    "    text=re_clear(text)\n",
    "    if lemmize==True:\n",
    "        text = text.apply(pymy)\n",
    "    pred = model.predict_proba(text)\n",
    "    return print(f\" Negative {pred[0][0]:.2%}, Positive {pred[0][1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fe=preprocessing.FunctionTransformer(FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu = pipeline.FeatureUnion([('idf',idf_vec),('fe',new_fe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   33.8s\n[Parallel(n_jobs=-1)]: Done  11 out of  30 | elapsed:   52.5s remaining:  1.5min\n[Parallel(n_jobs=-1)]: Done  15 out of  30 | elapsed:  1.3min remaining:  1.3min\n[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:  1.7min remaining:  1.0min\n[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  1.9min remaining:   34.2s\n[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  2.0min remaining:   13.4s\n[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.1min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'CV f1 score : 97.8975%'"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "pipe_fe = pipeline.Pipeline([('fu',fu),('clf',clf)])\n",
    "prms_fe = {'fu__idf__max_features':np.arange(100,5000,500),\n",
    "'fu__idf__ngram_range':[(1,1),(1,2),(2,2),(1,3),(2,3),(1,4)],\n",
    "'clf__alpha': [1,5,10,15,20,25,30,40,50,80]}\n",
    "rs_fe = model_selection.RandomizedSearchCV(pipe_fe,prms_fe,cv=3,scoring='f1',verbose=10,n_jobs=-1)\n",
    "rs_fe.fit(text,df.ttype)\n",
    "opt_pipe_fe = pipe_fe.set_params(**rs_fe.best_params_)\n",
    "opt_pipe_fe.fit(text,df.ttype)\n",
    "f\"CV f1 score : {np.mean(model_selection.cross_val_score(opt_pipe_fe,text,df.ttype,cv=3,scoring='f1')):0.4%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   11.9s\n[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   25.9s\n[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   43.6s\n[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   53.4s\n[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.3min\n[Parallel(n_jobs=-1)]: Done  44 out of  60 | elapsed:  1.5min remaining:   32.7s\n[Parallel(n_jobs=-1)]: Done  51 out of  60 | elapsed:  1.7min remaining:   17.8s\n[Parallel(n_jobs=-1)]: Done  58 out of  60 | elapsed:  1.8min remaining:    3.5s\n[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'CV f1 score : 72.6992%'"
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "sgd = linear_model.SGDClassifier()\n",
    "prms_sgd = {'idf__max_features':np.arange(100,5000,500),\n",
    "'idf__ngram_range':[(1,1),(1,2),(2,2),(1,3),(2,3),(1,4)],\n",
    "'clf__alpha': [0.00001,0.0001,0.001,0.01],\n",
    "'clf__penalty':['l2','l1','elasticnet'],\n",
    "'clf__loss':['perceptron','modified_huber']}\n",
    "pipe_sgd = pipeline.Pipeline([('idf',idf_vec),('clf',sgd)])\n",
    "rs_sgd = model_selection.RandomizedSearchCV(pipe_sgd,prms_sgd,cv=3,scoring='f1',verbose=10,n_jobs=-1,n_iter=20)\n",
    "rs_sgd.fit(text,df.ttype)\n",
    "opt_pipe_sgd = pipe_sgd.set_params(**rs_sgd.best_params_)\n",
    "opt_pipe_sgd.fit(text,df.ttype)\n",
    "f\"CV f1 score : {np.mean(model_selection.cross_val_score(opt_pipe_sgd,text,df.ttype,cv=5,scoring='f1')):0.4%}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Negative 100.00%, Positive 0.00%\n------------------------------------------------------------------------------------------------------------------------\n Negative 96.64%, Positive 3.36%\n------------------------------------------------------------------------------------------------------------------------\n Negative 80.67%, Positive 19.33%\n------------------------------------------------------------------------------------------------------------------------\n Negative 77.38%, Positive 22.62%\n------------------------------------------------------------------------------------------------------------------------\n Negative 52.99%, Positive 47.01%\n------------------------------------------------------------------------------------------------------------------------\n"
    }
   ],
   "source": [
    "for i in ['ужас какой то!','ну что за день(',\"эхх, жаль что ты вообще появился :C\",\"мда, неудачненько вышло...\",\" ну тут без комментариев\"]:\n",
    "    nlp(i,opt_pipe_sgd)\n",
    "    print('---'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Negative 0.00%, Positive 100.00%\n------------------------------------------------------------------------------------------------------------------------\n Negative 46.33%, Positive 53.67%\n------------------------------------------------------------------------------------------------------------------------\n Negative 23.89%, Positive 76.11%\n------------------------------------------------------------------------------------------------------------------------\n Negative 27.62%, Positive 72.38%\n------------------------------------------------------------------------------------------------------------------------\n Negative 46.33%, Positive 53.67%\n------------------------------------------------------------------------------------------------------------------------\n"
    }
   ],
   "source": [
    "for i in ['это хорошо','позитив',\"понравился вечер\",\" это просто моя любовь\",\"милота\"]:\n",
    "    nlp(i,opt_pipe_sgd)\n",
    "    print('---'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bita64dbd6c7d3c43dbacdceb6e15b93256"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}